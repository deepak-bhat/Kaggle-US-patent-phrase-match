{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Directory settings","metadata":{"papermill":{"duration":0.024515,"end_time":"2022-03-22T09:40:01.460332","exception":false,"start_time":"2022-03-22T09:40:01.435817","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import os\nINPUT_DIR = '../input/us-patent-phrase-to-phrase-matching/'\nOUTPUT_DIR = './'\nif not os.path.exists(OUTPUT_DIR):\n    os.makedirs(OUTPUT_DIR)","metadata":{"id":"fa3b873b","papermill":{"duration":0.041313,"end_time":"2022-03-22T09:40:01.526545","exception":false,"start_time":"2022-03-22T09:40:01.485232","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-17T18:42:52.639814Z","iopub.execute_input":"2022-06-17T18:42:52.640439Z","iopub.status.idle":"2022-06-17T18:42:52.671078Z","shell.execute_reply.started":"2022-06-17T18:42:52.640342Z","shell.execute_reply":"2022-06-17T18:42:52.670364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CFG_1:\n    num_workers=4\n    path=\"\"#\"../input/uspp-full-models/\"\n    config_path=\"\"#path+'seed_777_config.pth'\n    model=\"\"#\"microsoft/deberta-v3-large\"\n    batch_size=32\n    fc_dropout=\"\"#0.2\n    target_size=1\n    max_len=\"\"#140\n    seed=42\n    n_fold=4\n    trn_fold=[0, 1, 2, 3]","metadata":{"id":"48dd82bb","papermill":{"duration":0.033949,"end_time":"2022-03-22T09:40:01.634977","exception":false,"start_time":"2022-03-22T09:40:01.601028","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-17T18:42:52.679295Z","iopub.execute_input":"2022-06-17T18:42:52.679803Z","iopub.status.idle":"2022-06-17T18:42:52.684869Z","shell.execute_reply.started":"2022-06-17T18:42:52.679772Z","shell.execute_reply":"2022-06-17T18:42:52.683695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"use_title = True\nuse_sep = False\nsep = \"[s]\"\n\ndef seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True","metadata":{"execution":{"iopub.status.busy":"2022-06-17T18:42:52.709342Z","iopub.execute_input":"2022-06-17T18:42:52.710089Z","iopub.status.idle":"2022-06-17T18:42:52.715599Z","shell.execute_reply.started":"2022-06-17T18:42:52.710054Z","shell.execute_reply":"2022-06-17T18:42:52.714556Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Library","metadata":{"id":"f2ed8ef2","papermill":{"duration":0.038261,"end_time":"2022-03-22T09:40:10.626926","exception":false,"start_time":"2022-03-22T09:40:10.588665","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import os\nimport gc\nimport re\nimport ast\nimport sys\nimport copy\nimport json\nimport time\nimport math\nimport shutil\nimport string\nimport pickle\nimport random\nimport joblib\nimport itertools\nfrom pathlib import Path\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport scipy as sp\nimport numpy as np\nimport pandas as pd\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', 1000)\nfrom tqdm.auto import tqdm\nfrom sklearn.metrics import f1_score\nfrom sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n\nimport torch\nimport torch.nn as nn\nfrom torch.nn import Parameter\nimport torch.nn.functional as F\nfrom torch.optim import Adam, SGD, AdamW\nfrom torch.utils.data import DataLoader, Dataset\n\nimport tokenizers\nimport transformers\nfrom transformers import AutoTokenizer, AutoModel, AutoConfig\nfrom transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n%env TOKENIZERS_PARALLELISM=true\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"executionInfo":{"elapsed":20123,"status":"ok","timestamp":1644920080956,"user":{"displayName":"Yasufumi Nakama","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17486303986134302670"},"user_tz":-540},"id":"35916341","outputId":"06fa0ab8-a380-4f54-a98d-b7015b79d9e2","papermill":{"duration":26.143536,"end_time":"2022-03-22T09:40:36.798853","exception":false,"start_time":"2022-03-22T09:40:10.655317","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-17T18:42:52.744696Z","iopub.execute_input":"2022-06-17T18:42:52.744935Z","iopub.status.idle":"2022-06-17T18:43:01.441418Z","shell.execute_reply.started":"2022-06-17T18:42:52.744909Z","shell.execute_reply":"2022-06-17T18:43:01.440561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Utils","metadata":{"id":"fd586614","papermill":{"duration":0.032888,"end_time":"2022-03-22T09:40:36.865209","exception":false,"start_time":"2022-03-22T09:40:36.832321","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def get_score(y_true, y_pred):\n    score = sp.stats.pearsonr(y_true, y_pred)[0]\n    return score\n\n\ndef get_logger(filename=OUTPUT_DIR+'train'):\n    from logging import getLogger, INFO, StreamHandler, FileHandler, Formatter\n    logger = getLogger(__name__)\n    logger.setLevel(INFO)\n    handler1 = StreamHandler()\n    handler1.setFormatter(Formatter(\"%(message)s\"))\n    handler2 = FileHandler(filename=f\"{filename}.log\")\n    handler2.setFormatter(Formatter(\"%(message)s\"))\n    logger.addHandler(handler1)\n    logger.addHandler(handler2)\n    return logger\n\nLOGGER = get_logger()","metadata":{"id":"d5c0ccc6","papermill":{"duration":0.21551,"end_time":"2022-03-22T09:40:37.116848","exception":false,"start_time":"2022-03-22T09:40:36.901338","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-17T18:43:01.443154Z","iopub.execute_input":"2022-06-17T18:43:01.44373Z","iopub.status.idle":"2022-06-17T18:43:01.453438Z","shell.execute_reply.started":"2022-06-17T18:43:01.443689Z","shell.execute_reply":"2022-06-17T18:43:01.452443Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Loading","metadata":{"id":"cb3d8e1e","papermill":{"duration":0.032614,"end_time":"2022-03-22T09:40:37.184739","exception":false,"start_time":"2022-03-22T09:40:37.152125","status":"completed"},"tags":[]}},{"cell_type":"code","source":"test = pd.read_csv(INPUT_DIR+'test.csv')\nsubmission = pd.read_csv(INPUT_DIR+'sample_submission.csv')\n\ntitles = pd.read_csv('../input/cpc-codes/titles.csv', dtype=str)\ntest = test.merge(titles, left_on='context', right_on='code')\n\nif use_title:\n    if use_sep:\n        test['input'] = test.context + sep + test.title + sep + test.target + sep + test.anchor\n    else:\n        test['input'] = 'TEXT1: ' + test.context + ';TEXT2: ' + test.title + '; TEXT3: ' + test.target + '; ANC1: ' + test.anchor\nelse:\n    if use_sep:\n        test['input'] = test.context + sep + test.target + sep + test.anchor\n    else:\n        test['input'] = 'TEXT1: ' + test.context + '; TEXT2: ' + test.target + '; ANC1: ' + test.anchor              ","metadata":{"executionInfo":{"elapsed":2627,"status":"ok","timestamp":1644920084001,"user":{"displayName":"Yasufumi Nakama","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17486303986134302670"},"user_tz":-540},"id":"bef012d3","outputId":"d4d60dbc-510c-4f34-8d64-dd1d88c4808c","papermill":{"duration":0.154829,"end_time":"2022-03-22T09:40:37.374453","exception":false,"start_time":"2022-03-22T09:40:37.219624","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-17T18:43:01.455253Z","iopub.execute_input":"2022-06-17T18:43:01.455971Z","iopub.status.idle":"2022-06-17T18:43:02.382008Z","shell.execute_reply.started":"2022-06-17T18:43:01.455929Z","shell.execute_reply":"2022-06-17T18:43:02.381249Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def tok_func(x):\n    inputs = CFG_1.tokenizer(x,\n                  add_special_tokens=True,\n                  max_length=CFG_1.max_len,\n                  padding=\"max_length\",\n                  return_offsets_mapping=False)\n    for k, v in inputs.items():\n        inputs[k] = torch.tensor(v, dtype=torch.long)\n    return inputs\n\nclass TestDataset(Dataset):\n    def __init__(self,df):\n        self.texts = df['input'].values\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, item):\n        inputs = tok_func(self.texts[item])\n        return inputs","metadata":{"execution":{"iopub.status.busy":"2022-06-17T18:43:02.383927Z","iopub.execute_input":"2022-06-17T18:43:02.384363Z","iopub.status.idle":"2022-06-17T18:43:02.391949Z","shell.execute_reply.started":"2022-06-17T18:43:02.384326Z","shell.execute_reply":"2022-06-17T18:43:02.391282Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"###################Model################################\nclass CustomModel_Attn(nn.Module):\n    def __init__(self,cfg,config_path = None , pretrained = False):\n        super().__init__()\n        self.cfg = cfg\n        if config_path is None:\n            self.config = AutoConfig.from_pretrained(cfg.model_nm, output_hidden_states = True)\n        else:\n            self.config = torch.load(config_path)\n        \n        if pretrained:\n            self.model = AutoModel.from_pretrained(cfg.model_nm, config = self.config)\n        else:\n            self.model = AutoModel.from_config(self.config)\n        self.fc_dropout = nn.Dropout(cfg.fc_dropout)\n        self.fc = nn.Linear(self.config.hidden_size, self.cfg.target_size)\n        self._init_weights(self.fc)\n        self.attention = nn.Sequential(\n            nn.Linear(self.config.hidden_size, 512),\n            nn.Tanh(),\n            nn.Linear(512,1),\n            nn.Softmax(dim=1))\n        self._init_weights(self.attention)\n    \n    def _init_weights(self,module):\n        if isinstance(module,nn.Linear):\n            module.weight.data.normal_(mean = 0.0, std = self.config.initializer_range)\n            if module.bias is not None:\n                module.bias.data.zero_()\n        elif isinstance(module,nn.Embedding):\n            module.weight.data.normal_(mean = 0.0, std = self.config.initializer_range)\n            if module.padding_idx is not None:\n                module.weight.data[module.padding_idx].zero_()\n        elif isinstance(module,nn.LayerNorm):\n            module.bias.data.zero_()\n            module.weight.data.fill_(1.0)\n    \n    def feature(self, inputs):\n        outputs = self.model(**inputs)\n        last_hidden_states = outputs[0]\n        weights = self.attention(last_hidden_states)\n        feature = torch.sum(weights * last_hidden_states, dim =1)\n        return feature\n    \n    def forward(self,inputs):\n        feature = self.feature(inputs)\n        output = self.fc(self.fc_dropout(feature))\n        return output","metadata":{"id":"4c5bab44","papermill":{"duration":0.066203,"end_time":"2022-03-22T09:40:52.37203","exception":false,"start_time":"2022-03-22T09:40:52.305827","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-17T18:43:02.3931Z","iopub.execute_input":"2022-06-17T18:43:02.393564Z","iopub.status.idle":"2022-06-17T18:43:02.410113Z","shell.execute_reply.started":"2022-06-17T18:43:02.393501Z","shell.execute_reply":"2022-06-17T18:43:02.409318Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"###################Model################################\nclass CustomModel_Cls(nn.Module):\n    def __init__(self,cfg,config_path = None , pretrained = False):\n        super().__init__()\n        self.cfg = cfg\n        if config_path is None:\n            self.config = AutoConfig.from_pretrained(cfg.model_nm, output_hidden_states = True)\n        else:\n            self.config = torch.load(config_path)\n        \n        if pretrained:\n            self.model = AutoModel.from_pretrained(cfg.model_nm, config = self.config)\n        else:\n            self.model = AutoModel.from_config(self.config)\n        self.dropout = nn.Dropout(cfg.fc_dropout)\n        self.linear = nn.Linear(self.config.hidden_size,self.cfg.target_size)\n        self._init_weights(self.linear)\n#         self.relu = nn.ReLU()\n    \n    def _init_weights(self,module):\n        if isinstance(module,nn.Linear):\n            module.weight.data.normal_(mean = 0.0, std = self.config.initializer_range)\n            if module.bias is not None:\n                module.bias.data.zero_()\n        elif isinstance(module,nn.Embedding):\n            module.weight.data.normal_(mean = 0.0, std = self.config.initializer_range)\n            if module.padding_idx is not None:\n                module.weight.data[module.padding_idx].zero_()\n        elif isinstance(module,nn.LayerNorm):\n            module.bias.data.zero_()\n            module.weight.data.fill_(1.0)\n    \n    def forward(self,inputs):\n        output = self.model(**inputs)\n        cls_output = output['last_hidden_state'][:,0,:]\n        dropout_output = self.dropout(cls_output)\n        linear_output = self.linear(dropout_output)\n#         output = self.relu(linear_output)\n        return linear_output","metadata":{"execution":{"iopub.status.busy":"2022-06-17T18:43:02.412653Z","iopub.execute_input":"2022-06-17T18:43:02.412905Z","iopub.status.idle":"2022-06-17T18:43:02.428631Z","shell.execute_reply.started":"2022-06-17T18:43:02.412874Z","shell.execute_reply":"2022-06-17T18:43:02.427789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CustomModel_Ch(nn.Module):\n    def __init__(self, cfg, config_path=None, pretrained=False):\n        super().__init__()\n        self.cfg = cfg\n        if config_path is None:\n            self.config = AutoConfig.from_pretrained(cfg.model_nm, output_hidden_states=True)\n        else:\n            self.config = torch.load(config_path)\n        if pretrained:\n            self.model = AutoModel.from_pretrained(cfg.model_nm, config=self.config)\n        else:\n            self.model = AutoModel.from_config(self.config)\n        self.fc_dropout = nn.Dropout(cfg.fc_dropout)\n        self.fc = nn.Linear(self.config.hidden_size, self.cfg.target_size)\n        self._init_weights(self.fc)\n        self.attention = nn.Sequential(\n            nn.Linear(self.config.hidden_size, 512),\n            nn.Tanh(),\n            nn.Linear(512, 1),\n            nn.Softmax(dim=1)\n        )\n        self.layer_norm1 = nn.LayerNorm(self.config.hidden_size)\n        self._init_weights(self.attention)\n        self.linear = nn.Linear(self.config.hidden_size, 1)\n    def _init_weights(self, module):\n        if isinstance(module, nn.Linear):\n            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n            if module.bias is not None:\n                module.bias.data.zero_()\n        elif isinstance(module, nn.Embedding):\n            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n            if module.padding_idx is not None:\n                module.weight.data[module.padding_idx].zero_()\n        elif isinstance(module, nn.LayerNorm):\n            module.bias.data.zero_()\n            module.weight.data.fill_(1.0)\n        \n    def feature(self, inputs):\n        outputs = self.model(**inputs)\n        last_hidden_states = outputs[0]\n        # feature = torch.mean(last_hidden_states, 1)\n        weights = self.attention(last_hidden_states)\n        feature = torch.sum(weights * last_hidden_states, dim=1)\n        return feature\n\n    def forward(self, inputs):\n        outputs = self.model(**inputs)\n        last_hidden_state = outputs[0]\n        input_mask_expanded = inputs[\"attention_mask\"].unsqueeze(-1).expand(last_hidden_state.size()).float()\n        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n        sum_mask = input_mask_expanded.sum(1)\n        sum_mask = torch.clamp(sum_mask, min=1e-9)\n        out = sum_embeddings / sum_mask\n        \n        out = self.layer_norm1(out)\n        output = self.fc(out)\n        return output","metadata":{"execution":{"iopub.status.busy":"2022-06-17T18:43:02.430094Z","iopub.execute_input":"2022-06-17T18:43:02.430794Z","iopub.status.idle":"2022-06-17T18:43:02.4502Z","shell.execute_reply.started":"2022-06-17T18:43:02.430724Z","shell.execute_reply":"2022-06-17T18:43:02.449451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# inference","metadata":{"id":"deee9675","papermill":{"duration":0.044158,"end_time":"2022-03-22T09:40:52.460401","exception":false,"start_time":"2022-03-22T09:40:52.416243","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def inference_fn(test_loader, model, device):\n    preds = []\n    model.eval()\n    model.to(device)\n    tk0 = tqdm(test_loader, total=len(test_loader))\n    for inputs in tk0:\n        for k, v in inputs.items():\n            inputs[k] = v.to(device)\n        with torch.no_grad():\n            y_preds = model(inputs)\n        preds.append(y_preds.sigmoid().to('cpu').numpy())\n    predictions = np.concatenate(preds)\n    return predictions","metadata":{"execution":{"iopub.status.busy":"2022-06-17T18:43:02.45346Z","iopub.execute_input":"2022-06-17T18:43:02.453681Z","iopub.status.idle":"2022-06-17T18:43:02.465335Z","shell.execute_reply.started":"2022-06-17T18:43:02.453659Z","shell.execute_reply":"2022-06-17T18:43:02.464369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dataset = TestDataset(test)\ntest_loader = DataLoader(test_dataset,\n                         batch_size=CFG_1.batch_size,\n                         shuffle=False,\n                         num_workers=CFG_1.num_workers, pin_memory=True, drop_last=False)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-06-17T18:43:02.466729Z","iopub.execute_input":"2022-06-17T18:43:02.467216Z","iopub.status.idle":"2022-06-17T18:43:02.475701Z","shell.execute_reply.started":"2022-06-17T18:43:02.467175Z","shell.execute_reply":"2022-06-17T18:43:02.474893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_dict = { 1.01 : {'max_len' : 126,'fc_dropout' : 0.2 ,'seed' : 777,'model_nm' : \"bfp_attn\",\n                       'model_pth' : \"../input/usppm-101-bfp-attn/zip/\",'model' : '../input/bert-for-patents/bert-for-patents'},\n              1.07 : {'max_len' : 126,'fc_dropout' : 0.2,'seed' : 123,'model_nm' : \"bfp_attn\",\n                      'model_pth' :\"../input/usppm-107/zip/\",'model' : 'anferico/bert-for-patents'},\n              2.01 : {'max_len' : 140,'fc_dropout' : 0,'seed' : 42,'model_nm' : \"deberta_cls\",\n                      'model_pth' :\"../input/201-usppm-deberta-cls/\",'model' : 'microsoft/deberta-v3-large'},\n              3.01 : {'max_len' : 140,'fc_dropout' : 0.2,'seed' : 42,'model_nm' : \"deberta_attn\",\n                      'model_pth' :\"../input/usppm-301-deberta-attn/\",'model' : 'microsoft/deberta-v3-large'},\n              5.01 : {'max_len' : 140,'fc_dropout' : 0.2,'seed' : 42,'model_nm' : \"deberta_ch\",\n                      'model_pth' :\"../input/501-deberta-ch/\",'model' : 'microsoft/deberta-v3-large'},\n              5.02 : {'max_len' : 140,'fc_dropout' : 0.2,'seed' : 42,'model_nm' : \"deberta_ch\", \n                      'model_pth' :\"../input/502-deberta-ch/\",'model' : 'microsoft/deberta-v3-large'},\n              6.09 : {'max_len' : 117,'fc_dropout' : 0.15,'seed' : 42,'model_nm' : \"electra_ch\",\n                      'model_pth' :\"../input/usppm-609-electra/\",'model' : 'google/electra-large-discriminator'}\n             }","metadata":{"execution":{"iopub.status.busy":"2022-06-17T18:43:02.478663Z","iopub.execute_input":"2022-06-17T18:43:02.479038Z","iopub.status.idle":"2022-06-17T18:43:02.487593Z","shell.execute_reply.started":"2022-06-17T18:43:02.478994Z","shell.execute_reply":"2022-06-17T18:43:02.486818Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions_list = []\n\n######\n###Keep model order same as oof weighting list\n######\n\nmodel_list = [2.01,1.01,6.09,5.02,1.07,3.01] \nweight_list =[0.435, 0.205, 0.195, 0.390, 0.090]\nassert len(model_list) == len(weight_list)+1\n\nfor i,m in enumerate(model_list):\n    \n    CFG_1.seed = model_dict[m]['seed']\n    seed_everything(seed=CFG_1.seed)\n    \n    model_nm = model_dict[m]['model_nm']\n    CFG_1.path = model_dict[m]['model_pth']\n    CFG_1.fc_dropout = model_dict[m]['fc_dropout']\n    CFG_1.max_len = model_dict[m]['max_len']\n    CFG_1.model = model_dict[m]['model']\n    CFG_1.tokenizer = AutoTokenizer.from_pretrained(CFG_1.path+'tokenizer/')\n    CFG_1.config_path=CFG_1.path+'config.pth'\n    \n    model_predictions = []\n    for fold in  CFG_1.trn_fold:\n            \n        #choose right model class\n        if \"attn\" in model_nm:\n            model = CustomModel_Attn(CFG_1, config_path=CFG_1.config_path, pretrained=False)\n        elif \"cls\" in model_nm:\n            model = CustomModel_Cls(CFG_1, config_path=CFG_1.config_path, pretrained=False)\n        elif \"ch\" in model_nm:\n            model = CustomModel_Ch(CFG_1, config_path=CFG_1.config_path, pretrained=False)        \n        #load model weights\n        state = torch.load(CFG_1.path+f\"{CFG_1.model.replace('/', '-')}_fold{fold}_best.pth\",\n                       map_location=torch.device('cpu'))\n        model.load_state_dict(state['model'])\n        prediction = inference_fn(test_loader, model, device)\n        model_predictions.append(prediction)\n        del model, state, prediction; gc.collect()\n        torch.cuda.empty_cache()\n    model_predictions_mean = np.mean(model_predictions, axis=0)\n    predictions_list.append(model_predictions_mean)\n\nmd2 = predictions_list[0]\nfor i,k in enumerate(weight_list):\n    md2 = weight_list[i] * predictions_list[i+1] + (1-weight_list[i])*md2","metadata":{"execution":{"iopub.status.busy":"2022-06-17T18:43:37.606329Z","iopub.execute_input":"2022-06-17T18:43:37.606601Z","iopub.status.idle":"2022-06-17T18:46:00.757209Z","shell.execute_reply.started":"2022-06-17T18:43:37.606571Z","shell.execute_reply":"2022-06-17T18:46:00.756332Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"test['score'] = md2\ntest[['id', 'score']].to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-06-17T18:57:53.338526Z","iopub.execute_input":"2022-06-17T18:57:53.339279Z","iopub.status.idle":"2022-06-17T18:57:53.35223Z","shell.execute_reply.started":"2022-06-17T18:57:53.339231Z","shell.execute_reply":"2022-06-17T18:57:53.351367Z"},"trusted":true},"execution_count":null,"outputs":[]}]}